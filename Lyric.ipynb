{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 693: expected 4 fields, saw 5\\nSkipping line 752: expected 4 fields, saw 5\\nSkipping line 942: expected 4 fields, saw 5\\nSkipping line 955: expected 4 fields, saw 5\\n'\n",
      "  1%|          | 21041/1703499 [00:00<00:16, 101669.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences  1703499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1703499/1703499 [00:15<00:00, 112628.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# load all songs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "name_csv = 'MassiveFemaledatabase.csv'\n",
    "database = pd.read_csv(name_csv, error_bad_lines=False)\n",
    "\n",
    "\n",
    "maxlen = 20\n",
    "step = 1 # step size at every iteration\n",
    "sentences = [] # list of sequences\n",
    "next_chars = [] # list of next chracters that our model should predict\n",
    "text = \"\"\n",
    "for index, row in database['lyric'].iteritems():\n",
    "    text = text + str(row).lower()\n",
    "chars = sorted(list(set(text)))\n",
    "#print('total chars:', len(chars))\n",
    "# create a dictionary mapping chracter-to-index\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "# create a dictionary mapping index-to-chracter\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# cut the text into sequences\n",
    "\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "        \n",
    "print ('nb sequences ', len(sentences))\n",
    "for i, sentence in enumerate(tqdm(sentences)):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1703499/1703499 [==============================] - 283s 166us/step - loss: 1.7640\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "SRC = i wake up in the dream \n",
      "\n",
      "----- Generating with seed: \" wake up in the drea\"\n",
      "----loss :  1.763954773247968\n",
      "mon thing that you and i see it all i want to be something i'm a freak and i want to so water to so the start and i can see it i'm gonna got the start that i want to be the start in the good there we are it all the way i want to love you to be the start and i want to be a man i want the way i love you we to be your sead the start and i want to be the start on the start and i can't streed and i lik\n",
      "----- diversity: 0.5\n",
      "SRC = i wake up in the dream \n",
      "\n",
      "----- Generating with seed: \" wake up in the drea\"\n",
      "----loss :  1.763954773247968\n",
      "mans and you don't go bat of come this there on it a that that i'm so the say i'm a girl and i love you thing that you i'm got the got a camitess and i am i don't call that i'm the with a foorne show the love up the more free up and there the was on for and i want to be on the set you  in my hand of the sime and i could the start on the stard at the made fire it's go. i got a from the readin' and \n",
      "----- diversity: 1.0\n",
      "SRC = i wake up in the dream \n",
      "\n",
      "----- Generating with seed: \" wake up in the drea\"\n",
      "----loss :  1.763954773247968\n",
      "tle somaund old tructeris in my sal tire ever of a bo it's do your want and my never so beat it'ver lay you alo. take a let ma ne if you'll nve? see here all i'll me no them down rnow beame and grow don't think we do propsed  there now ain't it din't hear who so run too lising don't can hem\" dad as orty let the lines out our out think th. plan to dick don't get. the chucled you're loft a alweet 'c\n",
      "----- diversity: 1.2\n",
      "SRC = i wake up in the dream \n",
      "\n",
      "----- Generating with seed: \" wake up in the drea\"\n",
      "----loss :  1.763954773247968\n",
      "ms ar wromes and you lade a gatress goons thean geh. it've foget. up os my stim ored. i annere becker it's be your dirals by stronce. forget when i dart me. touch a back. it's dould't of me wrap you get strans. gut outoo  you're bead it weave? itgle hetergtle ney to devendit mo begievin' trabings why are iblandernes there and tolking. oh. ha-d  haw i ou? in your putchrnaple throwing wher in the cr\n",
      "Epoch 2/50\n",
      " 208000/1703499 [==>...........................] - ETA: 4:28 - loss: 1.5016"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.layers import LSTM , Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import re\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def search_last_model():\n",
    "    max_epoch = 0\n",
    "    for file in os.listdir(\"./\"):\n",
    "        if file.endswith(\".h5\"):\n",
    "            epoch = int(re.findall('\\d+', file )[0])\n",
    "            if epoch > max_epoch :\n",
    "                max_epoch = epoch\n",
    "                max_epoch_file = file\n",
    "        else :\n",
    "            max_epoch_file = None\n",
    "    if max_epoch_file != None:\n",
    "        model = load_model(max_epoch_file)\n",
    "        print (\"Load Mode =\", max_epoch_file)\n",
    "    else :\n",
    "        # create sequential network, because we are passing activations\n",
    "        # down the network\n",
    "        model = Sequential()\n",
    "        optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "        # add LSTM layer\n",
    "        model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "        # add Softmax layer to output one character\n",
    "        model.add(Dense(len(chars)))\n",
    "        model.add(Activation('softmax'))\n",
    "        # compile the model and pick the loss and optimizer\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer )\n",
    "        # train the model        \n",
    "        \n",
    "    return model , max_epoch\n",
    "            \n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "with open ('rpt.txt','w') as rpt:\n",
    "    rpt.write('epoch,lyric\\n')\n",
    "\n",
    "def on_epoch_end(epoch,logs ):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(src) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = src[start_index: start_index + maxlen]\n",
    "        print (\"SRC =\" , src , \"\\n\")\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        print ('----loss : ' ,logs['loss'])\n",
    "        for i in range(gen_length):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "            #print (x_pred)\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated = generated + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        with open ('rpt.txt','a') as rpt:\n",
    "            rpt.write(\"epoch = {}\\n\".format(epoch))\n",
    "            rpt.write(\"diversity = {}\\n\".format(diversity))\n",
    "            rpt.write(\"loss = {}\\n\".format(logs['loss']))\n",
    "            rpt.write(\"\\n\")\n",
    "            for buf in generated:\n",
    "                rpt.write(buf)\n",
    "            rpt.write(\"\\n\")\n",
    "            rpt.write(\"\\n\")\n",
    "            rpt.write(\"\\n\")\n",
    "        print()\n",
    "\n",
    "src = 'i wake up in the dream'\n",
    "gen_length = 400\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('model{epoch:08d}.h5', period=1, verbose=1 , save_best_only=True) \n",
    "\n",
    "model , last_epoch = search_last_model()\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer )\n",
    "model.fit(x, y, batch_size=128, initial_epoch=last_epoch , epochs=50,callbacks=[print_callback,checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "def load_model_gen():\n",
    "    start_index = random.randint(0, len(src) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = src[start_index: start_index + maxlen]\n",
    "        print (\"SRC =\" , src , \"\\n\")\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        for i in range(gen_length):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "            #print (x_pred)\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated = generated + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
